# Virtual models using faker candidates for testing failover behavior

models:
  # Virtual model with 3 faker candidates for failover testing
  "virtual:faker-test-failover":
    timeout: 30s
    candidates:
      - model: "faker:rate-limited"  # First candidate - will fail with rate limits
        timeout: 30s
      - model: "faker:no-json"       # Second candidate - different capabilities
        timeout: 30s
      - model: "faker:basic"         # Third candidate - should succeed
        timeout: 30s

  # Virtual model testing complete failure scenario
  "virtual:faker-test-all-fail":
    timeout: 30s
    candidates:
      - model: "faker:rate-limited"  # Will fail
        timeout: 30s
      - model: "faker:rate-limited"  # Will also fail
        timeout: 30s
      - model: "faker:rate-limited"  # Will also fail
        timeout: 30s

  # Benchmark routing test - YAML order: slow, medium, fast, unscored
  # With benchmark data, should be reordered to: fast, medium, slow, unscored
  "virtual:faker-benchmark-test":
    timeout: 30s
    routing:
      speed_weight: 1.0  # Default value score calculation
    candidates:
      - model: "faker:slow-provider"      # Slow - low value score, should move down
        timeout: 30s
      - model: "faker:medium-provider"    # Medium - middle value score
        timeout: 30s
      - model: "faker:fast-provider"      # Fast - high value score, should move up
        timeout: 30s
      - model: "faker:unscored-provider"  # No benchmark data, should stay last
        timeout: 30s

  # Benchmark routing test with speed_weight=2.0 (strongly favor speed)
  "virtual:faker-benchmark-speed-favor":
    timeout: 30s
    routing:
      speed_weight: 2.0  # Strongly favor speed
    candidates:
      - model: "faker:slow-provider"
        timeout: 30s
      - model: "faker:fast-provider"
        timeout: 30s

  # Benchmark routing test with priority override
  "virtual:faker-benchmark-priority":
    timeout: 30s
    routing:
      speed_weight: 1.0
    candidates:
      - model: "faker:slow-provider"
        timeout: 30s
        priority: always_first  # Should stay first despite low score
      - model: "faker:fast-provider"
        timeout: 30s
      - model: "faker:medium-provider"
        timeout: 30s

  # Virtual model for testing rate limit exhaustion failover
  # First candidate will exhaust rate limits, second should succeed
  "virtual:faker-rate-exhaust-failover":
    timeout: 60s
    candidates:
      - model: "faker:rate-exhaust"  # Will return 429s until rate limit retries exhausted
        timeout: 30s
      - model: "faker:basic"         # Second candidate - should succeed after first fails
        timeout: 30s

  # Virtual model for testing model-level failover (ModelError skips same model_reference)
  # Candidate 1 and 2 have same model_reference (faker_model_error)
  # Candidate 3 has different model_reference (faker_basic)
  # When candidate 1 fails with ModelError, candidate 2 should be skipped, candidate 3 should succeed
  "virtual:faker-model-error-failover":
    timeout: 60s
    candidates:
      - model: "faker:model-error"      # Will return ModelError
        timeout: 30s
      - model: "faker:model-error-alt"  # Same model_reference - should be SKIPPED
        timeout: 30s
      - model: "faker:basic"            # Different model_reference - should succeed
        timeout: 30s

  # Virtual model that chains to another virtual (tests recursive resolution)
  "virtual:faker-model-error-inner":
    timeout: 60s
    candidates:
      - model: "faker:model-error"      # Will return ModelError
        timeout: 30s
      - model: "faker:model-error-alt"  # Same model_reference - should be SKIPPED
        timeout: 30s

  # Virtual model chaining test: references another virtual + fallback
  "virtual:faker-chained-failover":
    timeout: 60s
    candidates:
      - model: "virtual:faker-model-error-inner"  # Will be flattened, both fail with same model_ref
      - model: "faker:basic"                       # Different model_reference - should succeed