# Cost-optimized infrastructure provider via OpenRouter
provider:
  base_provider: openrouter
  endpoint: https://openrouter.ai/api/v1
  headers:
    HTTP-Referer: https://github.com/guybrush1984/Elelem
    X-Title: Elelem
  default_params: {}
  extra_body:
    usage:
      include: true
    provider:
      only: ["cerebras"]
      allow_fallbacks: false

models:
  "cerebras@openrouter:openai/gpt-oss-120b?reasoning=@[low,medium,high]":
    metadata:
      model_reference: "openai_gpt_oss_120b"
      model_configuration: "reasoning=$reasoning"
    provider: cerebras@openrouter
    model_id: openai/gpt-oss-120b
    capabilities:
      supports_json_mode: false
      supports_temperature: true
      supports_system: true
    cost:
      input_cost_per_1m: 0.35
      output_cost_per_1m: 0.75
      currency: USD
    default_params:
      extra_body:
        reasoning:
          effort: $reasoning
  
  "cerebras@openrouter:meta-llama/llama-4-maverick-17b":
    provider: cerebras@openrouter
    model_id: meta-llama/llama-4-maverick
    capabilities:
      supports_json_mode: false
      supports_temperature: true
      supports_system: true
    cost:
      input_cost_per_1m: 0.20
      output_cost_per_1m: 0.60
      currency: USD      
    metadata:
      model_reference: "meta_llama4_maverick"

  "cerebras@openrouter:meta-llama/llama-4-scout-17b":
    provider: cerebras@openrouter
    model_id: meta-llama/llama-4-scout
    capabilities:
      supports_json_mode: false
      supports_temperature: true
      supports_system: true
    cost:
      input_cost_per_1m: 0.65
      output_cost_per_1m: 0.85
      currency: USD      
    metadata:
      model_reference: "meta_llama4_scout"  


      