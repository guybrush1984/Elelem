# Cost-optimized infrastructure provider via OpenRouter
provider:
  base_provider: openrouter
  endpoint: https://openrouter.ai/api/v1
  headers:
    HTTP-Referer: https://github.com/guybrush1984/Elelem
    X-Title: Elelem
  default_params: {}
  extra_body:
    usage:
      include: true
    provider:
      only: ["cerebras"]
      allow_fallbacks: false

models:
  "cerebras@openrouter:openai/gpt-oss-120b?reasoning=low":
    metadata:
      model_reference: "openai_gpt_oss_120b"
      model_configuration: "reasoning=low"
    provider: cerebras@openrouter
    model_id: openai/gpt-oss-120b
    capabilities:
      supports_json_mode: false
      supports_temperature: true
      supports_system: true
    cost: runtime
    default_params:
      extra_body:
        reasoning:
          effort: "low"

  "cerebras@openrouter:openai/gpt-oss-120b?reasoning=high":
    metadata:
      model_reference: "openai_gpt_oss_120b"
      model_configuration: "reasoning=high"
    provider: cerebras@openrouter
    model_id: openai/gpt-oss-120b
    capabilities:
      supports_json_mode: false
      supports_temperature: true
      supports_system: true
    cost: runtime
    default_params:
      extra_body:
        reasoning:
          effort: "high"
  
  "cerebras@openrouter:meta-llama/llama-4-maverick-17b":
    provider: cerebras@openrouter
    model_id: meta-llama/llama-4-maverick
    capabilities:
      supports_json_mode: false
      supports_temperature: true
      supports_system: true
    cost: runtime
    metadata:
      model_reference: "meta_llama4_maverick"

  "cerebras@openrouter:meta-llama/llama-4-scout-17b":
    provider: cerebras@openrouter
    model_id: meta-llama/llama-4-scout
    capabilities:
      supports_json_mode: false
      supports_temperature: true
      supports_system: true
    cost: runtime
    metadata:
      model_reference: "meta_llama4_scout"  