# Model definitions with capabilities and pricing for all supported providers
# Also includes provider endpoint configurations

# Provider configurations
providers:
  openai:
    endpoint: https://api.openai.com/v1
    fallback_model: openai:gpt-4.1
    default_params: {}
    
  groq:
    endpoint: https://api.groq.com/openai/v1
    fallback_model: groq:gpt-oss-120b
    default_params:
      service_tier: auto
      
  deepinfra:
    endpoint: https://api.deepinfra.com/v1/openai
    fallback_model: deepinfra:gpt-oss-120b
    default_params: {}
    
  scaleway:
    endpoint: https://api.scaleway.ai/v1
    fallback_model: scaleway:gpt-oss-120b
    default_params: {}
    
  openrouter:
    endpoint: https://openrouter.ai/api/v1
    fallback_model: openrouter:openai/gpt-4o-mini
    headers:
      HTTP-Referer: https://github.com/guybrush1984/Elelem
      X-Title: Elelem
    default_params: {}
    extra_body:
      usage:
        include: true

models:
  # OpenAI Models (Standard tier pricing)
  "openai:gpt-4.1":
    provider: openai
    model_id: gpt-4.1
    capabilities:
      supports_json_mode: true
      supports_temperature: true
      supports_system: true
    cost:
      input_cost_per_1m: 2.00  # $2.00 per 1M input tokens
      output_cost_per_1m: 8.00  # $8.00 per 1M output tokens
      currency: USD

  "openai:gpt-4.1-mini":
    provider: openai
    model_id: gpt-4.1-mini
    capabilities:
      supports_json_mode: true
      supports_temperature: true
      supports_system: true
    cost:
      input_cost_per_1m: 0.40  # $0.40 per 1M input tokens
      output_cost_per_1m: 1.60  # $1.60 per 1M output tokens
      currency: USD

  "openai:gpt-5":
    provider: openai
    model_id: gpt-5
    capabilities:
      supports_json_mode: true
      supports_temperature: false  # Only supports default temperature (1)
      supports_system: true
    cost:
      input_cost_per_1m: 1.25
      output_cost_per_1m: 10.00
      currency: USD

  "openai:gpt-5-mini":
    provider: openai
    model_id: gpt-5-mini
    capabilities:
      supports_json_mode: true
      supports_temperature: false  # Only supports default temperature (1)
      supports_system: true
    cost:
      input_cost_per_1m: 0.25
      output_cost_per_1m: 2.00
      currency: USD

  "openai:o3":
    provider: openai
    model_id: o3
    capabilities:
      supports_json_mode: true
      supports_temperature: false  # o-series models don't support temperature
    cost:
      input_cost_per_1m: 2.00
      output_cost_per_1m: 8.00
      currency: USD

  "openai:o3-mini":
    provider: openai
    model_id: o3-mini
    capabilities:
      supports_json_mode: true
      supports_temperature: false
      supports_system: true
    cost:
      input_cost_per_1m: 1.10
      output_cost_per_1m: 4.40
      currency: USD

  # GROQ Models
  "groq:openai/gpt-oss-120b":
    provider: groq
    model_id: openai/gpt-oss-120b  # GROQ's model ID format
    capabilities:
      supports_json_mode: true
      supports_temperature: true
      supports_system: true
    cost:
      input_cost_per_1m: 0.15
      output_cost_per_1m: 0.75
      currency: USD

  "groq:openai/gpt-oss-20b":
    provider: groq
    model_id: openai/gpt-oss-20b
    capabilities:
      supports_json_mode: true
      supports_temperature: true
      supports_system: true
    cost:
      input_cost_per_1m: 0.10
      output_cost_per_1m: 0.50
      currency: USD

  "groq:moonshotai/kimi-k2-instruct":
    provider: groq
    model_id: moonshotai/kimi-k2-instruct
    capabilities:
      supports_json_mode: true
      supports_temperature: true
      supports_system: true
    cost:
      input_cost_per_1m: 1.00
      output_cost_per_1m: 3.00
      currency: USD

  "groq:meta-llama/llama-4-maverick-17b-128e-instruct":
    provider: groq
    model_id: meta-llama/llama-4-maverick-17b-128e-instruct
    capabilities:
      supports_json_mode: true
      supports_temperature: true
      supports_system: true
    cost:
      input_cost_per_1m: 0.20
      output_cost_per_1m: 0.60
      currency: USD

  "groq:meta-llama/llama-4-scout-17b-16e-instruct":
    provider: groq
    model_id: meta-llama/llama-4-scout-17b-16e-instruct
    capabilities:
      supports_json_mode: true
      supports_temperature: true
      supports_system: true
    cost:
      input_cost_per_1m: 0.11
      output_cost_per_1m: 0.34
      currency: USD

  # DeepInfra Models - CRITICAL: ALL supports_json_mode = false
  "deepinfra:openai/gpt-oss-120b":
    provider: deepinfra
    model_id: openai/gpt-oss-120b
    capabilities:
      supports_json_mode: false  # DeepInfra doesn't support response_format
      supports_temperature: true
      supports_system: true
    cost:
      input_cost_per_1m: 0.09
      output_cost_per_1m: 0.45
      currency: USD

  "deepinfra:openai/gpt-oss-20b":
    provider: deepinfra
    model_id: openai/gpt-oss-20b
    capabilities:
      supports_json_mode: false
      supports_temperature: true
    cost:
      input_cost_per_1m: 0.04
      output_cost_per_1m: 0.16
      currency: USD

  "deepinfra:meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8":
    provider: deepinfra
    model_id: meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8
    capabilities:
      supports_json_mode: false
      supports_temperature: true
    cost:
      input_cost_per_1m: 0.08  # Need to verify - using Scout pricing as placeholder
      output_cost_per_1m: 0.30
      currency: USD

  "deepinfra:meta-llama/Llama-4-Scout-17B-16E-Instruct":
    provider: deepinfra
    model_id: meta-llama/Llama-4-Scout-17B-16E-Instruct
    capabilities:
      supports_json_mode: false
      supports_temperature: true
    cost:
      input_cost_per_1m: 0.08
      output_cost_per_1m: 0.30
      currency: USD

  "deepinfra:moonshotai/Kimi-K2-Instruct":
    provider: deepinfra
    model_id: moonshotai/Kimi-K2-Instruct
    capabilities:
      supports_json_mode: false
      supports_temperature: true
    cost:
      input_cost_per_1m: 0.50
      output_cost_per_1m: 2.00
      currency: USD

  "deepinfra:deepseek-ai/DeepSeek-R1-0528":
    provider: deepinfra
    model_id: deepseek-ai/DeepSeek-R1-0528
    capabilities:
      supports_json_mode: false
      supports_temperature: true
    cost:
      input_cost_per_1m: 0.50
      output_cost_per_1m: 2.15
      currency: USD

  "deepinfra:deepseek-ai/DeepSeek-V3.1":
    provider: deepinfra
    model_id: deepseek-ai/DeepSeek-V3.1
    capabilities:
      supports_json_mode: false
      supports_temperature: true
    cost:
      input_cost_per_1m: 0.30
      output_cost_per_1m: 1.00
      currency: USD

  "deepinfra:deepseek-ai/DeepSeek-R1-Distill-Llama-70B":
    provider: deepinfra
    model_id: deepseek-ai/DeepSeek-R1-Distill-Llama-70B
    capabilities:
      supports_json_mode: false
      supports_temperature: true
    cost:
      input_cost_per_1m: 0.10
      output_cost_per_1m: 0.40
      currency: USD

  "deepinfra:deepseek-ai/DeepSeek-R1-Distill-Qwen-32B":
    provider: deepinfra
    model_id: deepseek-ai/DeepSeek-R1-Distill-Qwen-32B
    capabilities:
      supports_json_mode: false
      supports_temperature: true
    cost:
      input_cost_per_1m: 0.075
      output_cost_per_1m: 0.15
      currency: USD

  # Scaleway Models (European data centers, EUR pricing converted to USD ~1.07 rate)
  "scaleway:gpt-oss-120b":
    provider: scaleway
    model_id: gpt-oss-120b
    capabilities:
      supports_json_mode: true
      supports_temperature: true
      supports_system: true
    cost:
      input_cost_per_1m: 0.16   # €0.15 → $0.16 USD
      output_cost_per_1m: 0.64  # €0.60 → $0.64 USD
      currency: USD

  "scaleway:gemma-3-27b-it":
    provider: scaleway
    model_id: gemma-3-27b-it
    capabilities:
      supports_json_mode: true
      supports_temperature: true
      supports_system: true
    cost:
      input_cost_per_1m: 0.27   # €0.25 → $0.27 USD
      output_cost_per_1m: 0.53  # €0.50 → $0.53 USD
      currency: USD

  "scaleway:mistral-small-3.2-24b-instruct-2506":
    provider: scaleway
    model_id: mistral-small-3.2-24b-instruct-2506
    capabilities:
      supports_json_mode: true
      supports_temperature: true
      supports_system: true
    cost:
      input_cost_per_1m: 0.16   # €0.15 → $0.16 USD
      output_cost_per_1m: 0.37  # €0.35 → $0.37 USD
      currency: USD

  "scaleway:qwen3-235b-a22b-instruct-2507":
    provider: scaleway
    model_id: qwen3-235b-a22b-instruct-2507
    capabilities:
      supports_json_mode: true
      supports_temperature: true
      supports_system: true
    cost:
      input_cost_per_1m: 0.80   # €0.75 → $0.80 USD
      output_cost_per_1m: 2.40  # €2.25 → $2.40 USD
      currency: USD

  # OpenRouter Models (Automatic provider routing with runtime pricing)
  "openrouter:openai/gpt-oss-20b":
    provider: openrouter
    model_id: openai/gpt-oss-20b  # Use :floor suffix to enforce price-first routing
    capabilities:
      supports_json_mode: false
      supports_temperature: true
      supports_system: true
    cost: runtime  # Costs determined at runtime from OpenRouter response headers

  # OpenRouter Models (Automatic provider routing with runtime pricing)
  "openrouter:openai/gpt-oss-120b":
    provider: openrouter
    model_id: openai/gpt-oss-120b  # Use :floor suffix to enforce price-first routing
    capabilities:
      supports_json_mode: false
      supports_temperature: true
      supports_system: true
    cost: runtime  # Costs determined at runtime from OpenRouter response headers

  # OpenRouter Models (Automatic provider routing with runtime pricing)
  "openrouter:anthropic/claude-sonnet-4":
    provider: openrouter
    model_id: anthropic/claude-sonnet-4  # Use :floor suffix to enforce price-first routing
    capabilities:
      supports_json_mode: false
      supports_temperature: true
      supports_system: true
    cost: runtime  # Costs determined at runtime from OpenRouter response headers

  # OpenRouter Models (Automatic provider routing with runtime pricing)
  "openrouter:mistralai/mixtral-8x22b-instruct":
    provider: openrouter
    model_id: mistralai/mixtral-8x22b-instruct  # Use :floor suffix to enforce price-first routing
    capabilities:
      supports_json_mode: false
      supports_temperature: true
      supports_system: true
    cost: runtime  # Costs determined at runtime from OpenRouter response headers

  # OpenRouter Models (Automatic provider routing with runtime pricing)
  "openrouter:mistralai/mistral-large-2411":
    provider: openrouter
    model_id: mistralai/mistral-large-2411  # Use :floor suffix to enforce price-first routing
    capabilities:
      supports_json_mode: false
      supports_temperature: true
      supports_system: true
    cost: runtime  # Costs determined at runtime from OpenRouter response headers 