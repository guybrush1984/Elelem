{
  "request": {
    "model": "fireworks:openai/gpt-oss-120b?low",
    "temperature": 0.1,
    "json_mode": false,
    "prompt_file": "small.yaml",
    "mode": "direct"
  },
  "error": {
    "message": "Model configuration error: Model 'fireworks:openai/gpt-oss-120b?low' not found in configuration",
    "type": "ValueError",
    "timestamp": "2025-09-17T16:18:34.085747"
  }
}