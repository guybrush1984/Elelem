# DeepInfra provider configuration and models
# CRITICAL: ALL supports_json_mode = false
provider:
  endpoint: https://api.deepinfra.com/v1/openai
  default_params: {}

models:
  "deepinfra:openai/gpt-oss-120b?reasoning=@[low,medium,high]":
    metadata:
      model_reference: "openai_gpt_oss_120b"
      model_configuration: "reasoning=$reasoning"
    provider: deepinfra
    model_id: openai/gpt-oss-120b
    capabilities:
      supports_json_mode: false  # DeepInfra doesn't support response_format
      supports_temperature: true
      supports_system: true
    cost:
      input_cost_per_1m: 0.09
      output_cost_per_1m: 0.45
      currency: USD
    default_params:
      reasoning_effort: $reasoning

  "deepinfra:openai/gpt-oss-20b?reasoning=@[low,medium,high]":
    metadata:
      model_reference: "openai_gpt_oss_20b"
      model_configuration: "reasoning=$reasoning"
    provider: deepinfra
    model_id: openai/gpt-oss-20b
    capabilities:
      supports_json_mode: false
      supports_temperature: true
    cost:
      input_cost_per_1m: 0.04
      output_cost_per_1m: 0.16
      currency: USD
    default_params:
      reasoning_effort: $reasoning  

  "deepinfra:meta-llama/llama-4-maverick-17b":
    metadata:
      model_reference: "meta_llama4_maverick"
    provider: deepinfra
    model_id: meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8
    capabilities:
      supports_json_mode: false
      supports_temperature: true
    cost:
      input_cost_per_1m: 0.08  # Need to verify - using Scout pricing as placeholder
      output_cost_per_1m: 0.30
      currency: USD

  "deepinfra:meta-llama/llama-4-scout-17b":
    metadata:
      model_reference: "meta_llama4_scout"
    provider: deepinfra
    model_id: meta-llama/Llama-4-Scout-17B-16E-Instruct
    capabilities:
      supports_json_mode: false
      supports_temperature: true
    cost:
      input_cost_per_1m: 0.08
      output_cost_per_1m: 0.30
      currency: USD

  "deepinfra:moonshotai/kimi-k2-instruct":
    metadata:
      model_reference: "moonshot_kimi_k2"
    provider: deepinfra
    model_id: moonshotai/Kimi-K2-Instruct
    capabilities:
      supports_json_mode: false
      supports_temperature: true
    cost:
      input_cost_per_1m: 0.50
      output_cost_per_1m: 2.00
      currency: USD

  "deepinfra:deepseek/deepseek-3.1":
    metadata:
      model_reference: "deepseek_v31"
    provider: deepinfra
    model_id: deepseek-ai/DeepSeek-V3.1
    capabilities:
      supports_json_mode: false
      supports_temperature: true
    cost:
      input_cost_per_1m: 0.30
      output_cost_per_1m: 1.00
      currency: USD

  "deepinfra:deepseek/deepseek-3.1?reasoning=@[low,medium,high]":
    metadata:
      model_reference: "deepseek_v31"
      model_configuration: "reasoning=$reasoning"
    provider: deepinfra
    model_id: deepseek-ai/DeepSeek-V3.1
    timeout: 300
    capabilities:
      supports_json_mode: false
      supports_temperature: true
    cost:
      input_cost_per_1m: 0.30
      output_cost_per_1m: 1.00
      currency: USD      
    default_params:
      stream: true    
      reasoning_effort: $reasoning

  "deepinfra:qwen/qwen3-30b-a3b?reasoning=@[none,high]":
    metadata:
      model_reference: "alibaba_qwen3_30b_a3b"
      model_configuration: "reasoning=$reasoning"
    provider: deepinfra
    model_id: Qwen/Qwen3-30B-A3B
    capabilities:
      supports_json_mode: false  
      supports_temperature: true
      supports_system: true
    cost:
      input_cost_per_1m: 0.08
      output_cost_per_1m: 0.29
      currency: USD
    default_params:
      stream: true
      reasoning_effort: $reasoning      

  "deepinfra:qwen/qwen3-235b-a22b?reasoning=@[none,high]":
    metadata:
      model_reference: "alibaba_qwen3_235b_a22b"
      model_configuration: "reasoning=$reasoning"
    provider: deepinfra
    model_id: Qwen/Qwen3-235B-A22B
    capabilities:
      supports_json_mode: false  
      supports_temperature: true
      supports_system: true
    cost:
      input_cost_per_1m: 0.18
      output_cost_per_1m: 0.54
      currency: USD
    default_params:
      stream: true
      reasoning_effort: $reasoning  


